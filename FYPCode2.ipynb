{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d6b5509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\admin\\anaconda3\\lib\\site-packages (4.0.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from gensim) (1.20.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from gensim) (1.6.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from gensim) (5.0.0)\n",
      "Requirement already satisfied: Cython==0.29.21 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from gensim) (0.29.21)\n",
      "Requirement already satisfied: keras in c:\\users\\admin\\anaconda3\\lib\\site-packages (2.4.3)\n",
      "Requirement already satisfied: h5py in c:\\users\\admin\\anaconda3\\lib\\site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from keras) (1.6.2)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from keras) (1.20.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\admin\\anaconda3\\lib\\site-packages (from keras) (5.4.1)\n",
      "Requirement already satisfied: six in c:\\users\\admin\\anaconda3\\lib\\site-packages (from h5py->keras) (1.15.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\admin\\anaconda3\\lib\\site-packages (1.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pandas) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim --upgrade\n",
    "!pip install keras --upgrade\n",
    "!pip install pandas --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dcb6419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.layers import Activation, Dense, Dropout, Embedding, Flatten, Conv1D, MaxPooling1D, LSTM\n",
    "from keras import utils\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.models import load_model\n",
    "\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2df24960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns  = [\"sentiment\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n",
    "\n",
    "data = pd.read_csv(r\"F:\\College\\Thesis\\Thesis code\\LargeSentimentTwitterData.csv\", \n",
    "                   encoding = \"ISO-8859-1\", names = columns)\n",
    "\n",
    "data = data[['sentiment','text']]\n",
    "data['sentiment'] = data['sentiment'].replace(4,1)\n",
    "\n",
    "ax = data.groupby('sentiment').count().plot(kind='bar', title='Distribution of data',\n",
    "                                               legend=False)\n",
    "ax.set_xticklabels(['Positive','Negative'], rotation=0)\n",
    "\n",
    "\n",
    "tweet = list(data['text'])\n",
    "sentiment = np.array(list(data['sentiment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b79840f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataProcess(textdata):\n",
    "    processedText = []\n",
    "    \n",
    "    wordLemm = WordNetLemmatizer()\n",
    "  \n",
    "    nonAlpha = \"[^a-zA-Z0-9]\"\n",
    "    \n",
    "    for tweet in textdata:\n",
    "        tweet = tweet.lower()   \n",
    "        \n",
    "        tweet = re.sub(nonAlpha, \" \", tweet)\n",
    "\n",
    "        tweetwords = ''\n",
    "        for word in tweet.split():\n",
    "            if len(word)>1:\n",
    "                word = wordLemm.lemmatize(word)\n",
    "                tweetwords += (word+' ')\n",
    "            \n",
    "        processedText.append(tweetwords)\n",
    "        \n",
    "    return processedText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32093299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Preprocessing complete.\n",
      "Time Taken: 84 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t = time.time()\n",
    "processedtext = dataProcess(tweet)\n",
    "print(f'Text Preprocessing complete.')\n",
    "print(f'Time Taken: {round(time.time()-t)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "884e99c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Split done.\n"
     ]
    }
   ],
   "source": [
    "xTrain, xTest, yTrain, yTest = train_test_split(processedtext, sentiment, test_size = 0.5, random_state = 0)\n",
    "\n",
    "print(f'Data Split done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c1aae5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token done.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(xTrain)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(xTrain)\n",
    "X_test = tokenizer.texts_to_sequences(xTest)\n",
    "\n",
    "print(f'Token done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f161789a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "vocabSize = len(tokenizer.word_index) + 1\n",
    "\n",
    "maxlen = 300\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "\n",
    "print(f'Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adc1fe97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "\n",
    "embeddings_dictionary = dict()\n",
    "glove_file = open(r'C:\\Users\\Admin\\Downloads\\glove.6B.100d.txt', encoding=\"utf8\")\n",
    "\n",
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary [word] = vector_dimensions\n",
    "glove_file.close()\n",
    "\n",
    "embedding_matrix = zeros((vocabSize, 100))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector\n",
    "        \n",
    "\n",
    "print(f'Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ca5f46a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 300, 100)          40260000  \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 30000)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 30001     \n",
      "=================================================================\n",
      "Total params: 40,290,001\n",
      "Trainable params: 30,001\n",
      "Non-trainable params: 40,260,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "embedding_layer = Embedding(vocabSize, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
    "model.add(embedding_layer)\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "61612524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1407/1407 [==============================] - 37s 26ms/step - loss: 0.5694 - acc: 0.7109 - val_loss: 0.5709 - val_acc: 0.7094\n",
      "Epoch 2/15\n",
      "1407/1407 [==============================] - 38s 27ms/step - loss: 0.5694 - acc: 0.7110 - val_loss: 0.5718 - val_acc: 0.7099\n",
      "Epoch 3/15\n",
      "1407/1407 [==============================] - 37s 27ms/step - loss: 0.5693 - acc: 0.7109 - val_loss: 0.5720 - val_acc: 0.7110\n",
      "Epoch 4/15\n",
      "1407/1407 [==============================] - 38s 27ms/step - loss: 0.5696 - acc: 0.7107 - val_loss: 0.5702 - val_acc: 0.7100\n",
      "Epoch 5/15\n",
      "1407/1407 [==============================] - 38s 27ms/step - loss: 0.5693 - acc: 0.7110 - val_loss: 0.5710 - val_acc: 0.7098\n",
      "Epoch 6/15\n",
      "1407/1407 [==============================] - 37s 27ms/step - loss: 0.5693 - acc: 0.7104 - val_loss: 0.5729 - val_acc: 0.7099\n",
      "Epoch 7/15\n",
      "1407/1407 [==============================] - 38s 27ms/step - loss: 0.5692 - acc: 0.7109 - val_loss: 0.5716 - val_acc: 0.7078\n",
      "Epoch 8/15\n",
      "1407/1407 [==============================] - 38s 27ms/step - loss: 0.5693 - acc: 0.7105 - val_loss: 0.5727 - val_acc: 0.7093\n",
      "Epoch 9/15\n",
      "1407/1407 [==============================] - 38s 27ms/step - loss: 0.5695 - acc: 0.7107 - val_loss: 0.5711 - val_acc: 0.7106\n",
      "Epoch 10/15\n",
      "1407/1407 [==============================] - 38s 27ms/step - loss: 0.5694 - acc: 0.7109 - val_loss: 0.5731 - val_acc: 0.7081\n",
      "Epoch 11/15\n",
      "1407/1407 [==============================] - 38s 27ms/step - loss: 0.5693 - acc: 0.7107 - val_loss: 0.5724 - val_acc: 0.7095\n",
      "Epoch 12/15\n",
      "1407/1407 [==============================] - 38s 27ms/step - loss: 0.5693 - acc: 0.7109 - val_loss: 0.5707 - val_acc: 0.7096\n",
      "Epoch 13/15\n",
      "1407/1407 [==============================] - 38s 27ms/step - loss: 0.5695 - acc: 0.7104 - val_loss: 0.5730 - val_acc: 0.7075\n",
      "Epoch 14/15\n",
      "1407/1407 [==============================] - 39s 28ms/step - loss: 0.5694 - acc: 0.7108 - val_loss: 0.5710 - val_acc: 0.7099\n",
      "Epoch 15/15\n",
      "1407/1407 [==============================] - 38s 27ms/step - loss: 0.5694 - acc: 0.7112 - val_loss: 0.5709 - val_acc: 0.7103\n",
      "25000/25000 [==============================] - 56s 2ms/step - loss: 0.5706 - acc: 0.7099\n",
      "Test Score: 0.5705851316452026\n",
      "Test Accuracy: 0.7098837494850159\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, yTrain, batch_size=512, epochs=15, verbose=1, validation_split=0.1)\n",
    "\n",
    "score = model.evaluate(X_test, yTest, verbose=1)\n",
    "\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05b0bdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 300, 100)          40260000  \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 296, 128)          64128     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 40,324,257\n",
      "Trainable params: 64,257\n",
      "Non-trainable params: 40,260,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "embedding_layer = Embedding(vocabSize, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
    "model2.add(embedding_layer)\n",
    "\n",
    "model2.add(Conv1D(128, 5, activation='relu'))\n",
    "model2.add(GlobalMaxPooling1D())\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b26a91f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "352/352 [==============================] - 513s 1s/step - loss: 0.5468 - acc: 0.7189 - val_loss: 0.4939 - val_acc: 0.7606\n",
      "Epoch 2/10\n",
      "352/352 [==============================] - 429s 1s/step - loss: 0.4770 - acc: 0.7717 - val_loss: 0.4724 - val_acc: 0.7746\n",
      "Epoch 3/10\n",
      "352/352 [==============================] - 428s 1s/step - loss: 0.4556 - acc: 0.7857 - val_loss: 0.4607 - val_acc: 0.7833\n",
      "Epoch 4/10\n",
      "352/352 [==============================] - 428s 1s/step - loss: 0.4423 - acc: 0.7937 - val_loss: 0.4574 - val_acc: 0.7852\n",
      "Epoch 5/10\n",
      "352/352 [==============================] - 429s 1s/step - loss: 0.4339 - acc: 0.7988 - val_loss: 0.4531 - val_acc: 0.7882\n",
      "Epoch 6/10\n",
      "352/352 [==============================] - 428s 1s/step - loss: 0.4252 - acc: 0.8041 - val_loss: 0.4542 - val_acc: 0.7871\n",
      "Epoch 7/10\n",
      "352/352 [==============================] - 429s 1s/step - loss: 0.4194 - acc: 0.8076 - val_loss: 0.4626 - val_acc: 0.7828\n",
      "Epoch 8/10\n",
      "352/352 [==============================] - 429s 1s/step - loss: 0.4138 - acc: 0.8105 - val_loss: 0.4557 - val_acc: 0.7876\n",
      "Epoch 9/10\n",
      "352/352 [==============================] - 428s 1s/step - loss: 0.4089 - acc: 0.8134 - val_loss: 0.4577 - val_acc: 0.7846\n",
      "Epoch 10/10\n",
      "352/352 [==============================] - 428s 1s/step - loss: 0.4067 - acc: 0.8146 - val_loss: 0.4587 - val_acc: 0.7848\n",
      "25000/25000 [==============================] - 191s 8ms/step - loss: 0.4539 - acc: 0.7863\n",
      "Test Score: 0.4538748562335968\n",
      "Test Accuracy: 0.7863487601280212\n"
     ]
    }
   ],
   "source": [
    "history = model2.fit(X_train, yTrain, batch_size=2048, epochs=10, verbose=1, validation_split=0.1)\n",
    "\n",
    "score = model2.evaluate(X_test, yTest, verbose=1)\n",
    "\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b592efb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "model2.save(\"CNNModel.h5\")\n",
    "print(f'Model Saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10791803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.18.5\n",
      "  Downloading numpy-1.18.5-cp38-cp38-win_amd64.whl (12.8 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.20.1\n",
      "    Uninstalling numpy-1.20.1:\n",
      "      Successfully uninstalled numpy-1.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\Admin\\\\anaconda3\\\\Lib\\\\site-packages\\\\~umpy\\\\core\\\\_multiarray_tests.cp38-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install -U numpy==1.18.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2835b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 300, 100)          40260000  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 40,377,377\n",
      "Trainable params: 117,377\n",
      "Non-trainable params: 40,260,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "embedding_layer = Embedding(vocabSize, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
    "model3.add(embedding_layer)\n",
    "model3.add(LSTM(128))\n",
    "\n",
    "model3.add(Dense(1, activation='sigmoid'))\n",
    "model3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "print(model3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e324433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "176/176 [==============================] - 1888s 11s/step - loss: 0.6932 - acc: 0.4997 - val_loss: 0.6931 - val_acc: 0.5001\n",
      "Epoch 2/10\n",
      "176/176 [==============================] - 1884s 11s/step - loss: 0.6932 - acc: 0.4991 - val_loss: 0.6931 - val_acc: 0.4999\n",
      "Epoch 3/10\n",
      "176/176 [==============================] - 1877s 11s/step - loss: 0.6932 - acc: 0.4989 - val_loss: 0.6931 - val_acc: 0.5001\n",
      "Epoch 4/10\n",
      "176/176 [==============================] - 1876s 11s/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.4999\n",
      "Epoch 5/10\n",
      "176/176 [==============================] - 1889s 11s/step - loss: 0.6932 - acc: 0.4995 - val_loss: 0.6932 - val_acc: 0.4999\n",
      "Epoch 6/10\n",
      "176/176 [==============================] - 1890s 11s/step - loss: 0.6932 - acc: 0.5003 - val_loss: 0.6931 - val_acc: 0.5001\n",
      "Epoch 7/10\n",
      "176/176 [==============================] - 1885s 11s/step - loss: 0.6932 - acc: 0.4994 - val_loss: 0.6932 - val_acc: 0.4999\n",
      "Epoch 8/10\n",
      "176/176 [==============================] - 1879s 11s/step - loss: 0.6932 - acc: 0.4993 - val_loss: 0.6931 - val_acc: 0.5001\n",
      "Epoch 9/10\n",
      "176/176 [==============================] - 1878s 11s/step - loss: 0.6932 - acc: 0.4996 - val_loss: 0.6931 - val_acc: 0.5001\n",
      "Epoch 10/10\n",
      "176/176 [==============================] - 1881s 11s/step - loss: 0.6931 - acc: 0.4994 - val_loss: 0.6931 - val_acc: 0.4999\n",
      "25000/25000 [==============================] - 1261s 50ms/step - loss: 0.6933 - acc: 0.5003\n",
      "Test Score: 0.6932849287986755\n",
      "Test Accuracy: 0.5003112554550171\n"
     ]
    }
   ],
   "source": [
    "history = model3.fit(X_train, yTrain, batch_size=4096, epochs=10, verbose=1, validation_split=0.1)\n",
    "\n",
    "score = model3.evaluate(X_test, yTest, verbose=1)\n",
    "\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "\n",
    "model3.save(\"LSTM_Model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d61c5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288\n",
      "112\n",
      "['Negative', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Negative', 'Negative', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Negative', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Negative', 'Positive', 'Negative', 'Negative', 'Negative', 'Negative', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Negative', 'Positive', 'Negative', 'Positive', 'Positive', 'Negative', 'Positive', 'Negative', 'Positive', 'Positive', 'Negative', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Negative', 'Negative', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Negative', 'Negative', 'Negative', 'Positive', 'Positive', 'Negative', 'Negative', 'Positive', 'Negative', 'Positive', 'Positive', 'Negative', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Negative', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Negative', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Negative', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Negative', 'Negative', 'Positive', 'Positive', 'Positive', 'Negative', 'Negative', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Negative', 'Positive', 'Negative', 'Negative', 'Positive', 'Negative', 'Negative', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Negative', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Negative', 'Positive', 'Negative', 'Negative', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Negative', 'Negative', 'Positive', 'Negative', 'Negative', 'Positive', 'Positive', 'Negative', 'Negative', 'Positive', 'Positive', 'Negative', 'Negative', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Negative', 'Positive', 'Positive', 'Negative', 'Positive', 'Negative', 'Negative', 'Positive', 'Positive', 'Negative', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Negative', 'Negative', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Negative', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive']\n"
     ]
    }
   ],
   "source": [
    "def predict(text, model):\n",
    "    \n",
    "   \n",
    "    x_test = pad_sequences(tokenizer.texts_to_sequences([text]), maxlen=300)\n",
    "    \n",
    "    score = model.predict([x_test])[0]\n",
    "    posCount = 0\n",
    "    negCount = 0\n",
    "    label = ''\n",
    "    if score < 0.5:\n",
    "        label = 'Negative'\n",
    "        negCount += 1\n",
    "    else:\n",
    "        label = 'Positive'\n",
    "        posCount += 1\n",
    "    \n",
    "\n",
    "    return label , posCount, negCount \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    \n",
    "    model = load_model('CNNModel.h5')\n",
    "    columns  = [\"sentiment\",\"text\"]\n",
    "    \n",
    "    text = pd.read_csv(r\"F:\\College\\Thesis\\Thesis code\\train200.csv\", \n",
    "                       encoding = \"ISO-8859-1\", names = columns)\n",
    "    \n",
    "    text = list(text['text'])\n",
    "    totalP = 0\n",
    "    totalN = 0\n",
    "    newList = []\n",
    "    for item in text:\n",
    "        label, countP, countN = predict(item, model)\n",
    "        totalP += countP\n",
    "        totalN += countN\n",
    "        newList.append(label)\n",
    "        \n",
    "        \n",
    "    print(totalP)\n",
    "    print(totalN)\n",
    "    print(newList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d5d81bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Positive', 'Negative', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Negative', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Negative', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Negative', 'Negative', 'Positive', 'Positive', 'Positive', 'Negative', 'Negative', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Negative', 'Positive', 'Negative', 'Negative', 'Positive', 'Negative', 'Negative', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Negative', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Negative', 'Positive', 'Negative', 'Negative', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Negative', 'Negative', 'Positive', 'Negative', 'Negative', 'Positive', 'Positive', 'Negative', 'Negative', 'Positive', 'Positive', 'Negative', 'Negative', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Negative', 'Positive', 'Positive', 'Negative', 'Positive', 'Negative', 'Negative', 'Positive', 'Positive', 'Negative', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Negative', 'Negative', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Negative', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive']\n"
     ]
    }
   ],
   "source": [
    "print(newList[-200:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5fef11b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (<ipython-input-13-77a5fa45b0cc>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-13-77a5fa45b0cc>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    converter = tf.lite.TFLiteConverter.from_saved_model('C:\\Users\\Admin\\CNNModel.h5') # path to the SavedModel directory\u001b[0m\n\u001b[1;37m                                                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model('C:\\Users\\Admin\\CNNModel.h5') # path to the SavedModel directory\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1b0d3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\Admin\\AppData\\Local\\Temp\\tmp2sm126ff\\assets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "model = load_model('CNNModel.h5')\n",
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model) # path to the SavedModel directory\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('CNNModel.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6177a13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1 300]\n",
      "<class 'numpy.float32'>\n",
      "[1 1]\n",
      "<class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=\"CNNModel.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Print input shape and type\n",
    "print(interpreter.get_input_details()[0]['shape'])  # Example: [1 224 224 3]\n",
    "print(interpreter.get_input_details()[0]['dtype'])  # Example: <class 'numpy.float32'>\n",
    "\n",
    "# Print output shape and type\n",
    "print(interpreter.get_output_details()[0]['shape'])  # Example: [1 1000]\n",
    "print(interpreter.get_output_details()[0]['dtype'])  # Example: <class 'numpy.float32'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b7568f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3422e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
